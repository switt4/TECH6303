{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/switt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/switt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "#from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(path=\"imdb.npz\", maxlen=130, num_words=6000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6169,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing import sequence\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=130)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=130) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#np_load_old = np.load\n",
    "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an RNN with the following layers:\n",
    "#1.An embedding layer with the following parameters:\n",
    "    #The input dimension is 6000.\n",
    "    #The output dimension is 128.\n",
    "    #The input length is 130.\n",
    "model.add(tf.keras.layers.Embedding(input_dim=6000, output_dim=128, input_length=130))\n",
    "\n",
    "#2. An LSTM layer with 32 units.\n",
    "model.add(tf.keras.layers.LSTM(32))\n",
    "\n",
    "#3. A fully connected layer with the following parameters:\n",
    "    #Activation function is ReLU.\n",
    "    #The number of units is 20.\n",
    "model.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "\n",
    "#4. A dropout layer with a dropout rate of 5%.\n",
    "model.add(tf.keras.layers.Dropout(0.05))\n",
    "\n",
    "#5.A fully connected layer with the following parameters:\n",
    "    #Activation function is sigmoid.\n",
    "    #The number of units is 1.\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 130, 128)          768000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 789,289\n",
      "Trainable params: 789,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer: Adam\n",
    "#Loss function: binary_crossentropy\n",
    "#Metrics: accuracy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 5s 83ms/step - loss: 0.6240 - accuracy: 0.6563\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 5s 77ms/step - loss: 0.3145 - accuracy: 0.8745\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 0.1597 - accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 6s 104ms/step - loss: 0.0950 - accuracy: 0.9697\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 5s 84ms/step - loss: 0.0460 - accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x645b65410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Epochs: 5\n",
    "#Batch size: 100\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 2s 9ms/step - loss: 0.4867 - accuracy: 0.8486\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4866587817668915\n",
      "accuracy: 0.8485679626464844\n"
     ]
    }
   ],
   "source": [
    "print(\"loss:\",loss)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
